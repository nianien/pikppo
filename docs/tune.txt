行，给你一份完整、可落地、可扩展、不会再写死词表的 ASR tune 调参方案。
目标很明确：只拿“有 vozo gold（*_original_subtitles.srt）”的视频做测试，对 Whisper / FunASR 的多个参数组合跑完以后，用 gold 自动打分选最优。所有输出都落在 videos/jljw/test/。

⸻

0. 你要的最终效果
	•	自动扫描 videos/jljw/
	•	只处理满足：<stem>.mp4 + <stem>_original_subtitles.srt 的集
	•	每集产出：
	•	预处理音频（raw/vocals 可选）
	•	Whisper 多组参数输出多个 SRT
	•	FunASR 多组配置输出多个 SRT
	•	eval.json（每个 trial 的详细分数）
	•	best.json（本集最优 trial）
	•	全局产出：
	•	videos/jljw/test/summary/trials.csv
	•	best_overall.json（跨集最优默认配置）
	•	best_per_episode.csv（每集最优，给你做 fallback）

⸻

1. 目录结构（只用 videos/jljw/test）

videos/jljw/
├── *.mp4
├── *_original_subtitles.srt
└── test/
    ├── <stem>/
    │   ├── audio/
    │   │   ├── raw-16k.wav
    │   │   └── vocals-16k.wav          (可选)
    │   ├── whisper/
    │   │   ├── w_small_int8_ns0.4_raw.srt
    │   │   ├── w_small_int8_ns0.5_raw.srt
    │   │   └── ...
    │   ├── funasr/
    │   │   ├── f_paraformer_raw.srt
    │   │   └── ...
    │   ├── eval.json
    │   └── best.json
    └── summary/
        ├── trials.csv
        ├── best_overall.json
        └── best_per_episode.csv

幂等规则：文件存在就跳过（除非你传 --force）。

⸻

2. 只选“有 gold 的视频”作为数据集

扫描规则：
	•	遍历 videos/jljw/*.mp4
	•	对每个 <stem>.mp4，检查 videos/jljw/<stem>_original_subtitles.srt
	•	找不到就 skip

⸻

3. 试验空间（别发散，先收敛）

3.1 Whisper（CPU）

固定不动（字幕稳定优先）：
	•	temperature=0.0
	•	condition_on_previous_text=False
	•	vad_filter=False（不折叠时间轴）
	•	language="zh"

调参维度（够用了）：
	•	audio_input: raw / vocals（可选）
	•	model_size: small（必要时加 medium）
	•	compute_type: int8 / float32（mac CPU 安全）
	•	no_speech_threshold: [0.4, 0.5, 0.6]（别再用 0.2）
	•	beam_size: [3, 5]
	•	best_of: [3, 5]

组合规模（默认 small+int8+raw/vocals）：
2 * 3 * 2 * 2 = 24 / 集 —— 完全可控。

3.2 FunASR（备选/对照）

FunASR 你别搞几十种参数，搞 2–6 个“配置档”就行：
	•	paraformer（中文通用）
	•	paraformer-large（更准更慢）
	•	视你的 wrapper：标点开/关、VAD 开/关（注意不要折叠时间轴）

输出同样生成 SRT，用同一评分器评分。

⸻

4. 音频预处理（固定标准）

raw-16k（必须）

从 mp4 提取，16k mono：

ffmpeg -y -i <video.mp4> -ar 16000 -ac 1 -af dynaudnorm -acodec pcm_s16le raw-16k.wav

vocals-16k（可选，但建议）

如果你要试 vocals，就必须先“降伪影”，不要裸 dynaudnorm：

ffmpeg -y -i vocals.wav -ar 16000 -ac 1 -af "afftdn,dynaudnorm" -acodec pcm_s16le vocals-16k.wav

vocals 很可能更差（Demucs 伪影 + 口腔辅音损伤），所以必须用调参器客观选，不要迷信。

⸻

5. 评分体系（字幕专用，核心：宁可少，不可乱）

你之前喷点对：CALL_WORDS 写死是垃圾。
这里直接给你动态学习版，从 gold 自动学习“这部剧的分布”，然后惩罚“pred 高频但 gold 低频”的短碎片。

5.1 对齐方式：按时间重叠匹配
	•	以 pred 每条为单位，找 overlap 最大的 gold
	•	overlap < 0.15s 就认为不匹配

5.2 分项指标

每个 trial 都算这些：
	1.	Coverage（覆盖率）
gold 有字幕的条目里，有多少被 pred 覆盖（按时间 overlap）

字幕任务里 coverage 很关键，漏太多也不行

	2.	Text similarity（句级相似度）
匹配到的 pred/gold，算 LCS ratio（中文很好用）

不追求逐字，但追求“像一句话”

	3.	Overtalk penalty（乱说惩罚）
pred 在 gold 空白时间段输出的比例

你 v2 崩就是这个指标爆了

	4.	Fragmentation penalty（碎片惩罚）
2–3 字短行占比、行数过多都扣分
	5.	Repeat penalty（刷屏惩罚）
相邻重复行比例
	6.	✅ Dynamic hallucination token penalty（核心升级）
从 pred 里抽取 2–4 字短句 token，找：

	•	pred 出现次数 ≥ 3
	•	且 gold 里为 0 或 pred ≥ 4 * gold
这些就是“这部剧里不该高频出现，但模型在刷”的胡说 token
用它们在 pred 短句中的占比作为惩罚。

这比你写死“天哥/小二”高级一百倍：自动适配新剧。

5.3 总分（建议权重）

字幕偏克制：

score =
  0.38 * coverage
+ 0.32 * similarity
- 0.16 * overtalk
- 0.08 * short_fragment
- 0.04 * repeat
- 0.02 * hallu_tokens   # 动态学习出来的胡说 token


⸻

6. 选择最优的规则（全局 + 每集）

你要两个输出：

6.1 best_per_episode（每集最优）

每集挑 score 最高的 trial，写到：
	•	videos/jljw/test/<stem>/best.json
	•	summary/best_per_episode.csv

6.2 best_overall（默认上线配置）

跨集汇总同一个 trial config 的得分：
	•	平均分最高为第一候选
	•	同时看 min 分不要崩（避免某集爆炸）

写到：
	•	summary/best_overall.json

⸻

7. 程序结构（你要写成一个 tune 脚本就行）

建议就一个脚本：tools/tune_jljw.py，主流程：
	1.	scan episodes（只挑有 gold 的）
	2.	per episode：
	•	ensure raw-16k.wav
	•	(optional) ensure vocals-16k.wav
	•	run whisper trials → 输出多个 whisper/*.srt
	•	run funasr trials → 输出多个 funasr/*.srt
	•	eval all trials → eval.json
	•	pick best → best.json
	3.	summary：
	•	trials.csv
	•	best_overall.json
	•	best_per_episode.csv

⸻

8. 命令行设计（简单且不恶心）

你要 Maven lifecycle 那种味道，可以这么做（不逼你用 runs）：

# 只跑评估需要的数据（扫描+音频）
python tools/tune_jljw.py prep --root videos/jljw --vocals

# 跑 whisper 全部 trial
python tools/tune_jljw.py whisper --root videos/jljw --model small --compute int8

# 跑 funasr trial（如果你装好了）
python tools/tune_jljw.py funasr --root videos/jljw

# 打分+汇总（也可一键 all）
python tools/tune_jljw.py eval --root videos/jljw
python tools/tune_jljw.py all --root videos/jljw --vocals --model small --compute int8

所有输出固定写入 videos/jljw/test/。

⸻

9. 最关键的落地注意事项（避免你再踩坑）
	•	不要再把 no_speech_threshold 拉到 0.2：在你这种短剧+人声分离+归一化的组合下，极容易过度解码。
	•	vocals 不是必然更好：必须让 tune 用 gold 投票决定。
	•	评分指标必须“压胡说”：否则调参会被“多输出=覆盖率高”误导。
	•	动态 hallu token 惩罚是必需品：换剧不用改词表，才能规模化。

⸻

10. 你要我下一步给什么

你现在一句话回复我：
你希望 tune 同时跑 FunASR 吗？
	•	如果 不跑 FunASR：我直接给你一份完整可运行的 tools/tune_jljw.py（Whisper 全流程 + 动态 hallu token + summary），你立刻能用。
	•	如果 要跑 FunASR：你把你项目里 FunASR 的调用入口（哪个文件/哪个函数）贴出来，我会把 FunASR trial 也接上，同样输出 SRT 同样打分。