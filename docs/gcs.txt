下面给你一份完整、可落地、按你当前工程约束（每集≤3分钟；xxxx/1.mp4,2.mp4；输出到 xxxx/dub/1,xxxx/dub/2；v1 追求稳定） 的整改方案。重点解决你现在踩的两个坑：
	•	Google STT inline payload 10MB / duration limit
	•	Demucs 输出音频过大导致 chunk 逻辑失效/复杂

并顺带把 v1 的 ASR/TTS 缓存与目录规范一次定死（episode 维度）。

⸻

0. 总目标（v1）

对每集视频（≤3分钟）跑通一条稳定流水线：
	1.	Extract audio
	2.	Vocals separation（Demucs）
	3.	ASR（Google Speech-to-Text）+ diarization
	4.	翻译（OpenAI/Gemini）
	5.	TTS（Azure）
	6.	对齐 & 混音 & 输出

整改后关键变化：
	•	ASR 不再用 inline bytes，统一改成 GCS URI
	•	不再切分 chunk（≤3分钟没必要）
	•	Demucs 输出先强制转 16k mono LINEAR16，保证体积稳定、识别稳定
	•	缓存按 episode 目录保存（可选项，强烈建议）

⸻

1. 目录与产物规范（保持你要求的命名）

输入：
	•	xxxx/1.mp4
	•	xxxx/2.mp4

输出：
	•	xxxx/dub/1/
	•	xxxx/dub/2/

以 1.mp4 为例，最终目录应为：

xxxx/dub/1/
  1.wav                      # 提取的原始音频（可选保留）
  1-vocals.wav               # demucs 输出（原格式，建议保留用于排查）
  1-vocals-16k.wav           # ✅ 16k mono pcm（ASR 输入，关键产物）
  1-zh.srt                   # ASR 输出
  1-en.srt                   # 翻译输出
  1-tts.wav                  # TTS 拼接输出
  1-tts-aligned.wav          # 对齐后的 TTS
  1-final.mp4                # 最终合成（可选）
  .temp/                     # 运行期临时（可删）
  .cache/                    # episode 级缓存（可选）


⸻

2. GCP 侧整改（一次性）

2.1 建一个 GCS bucket（必须）

用途：把 1-vocals-16k.wav 上传到 GCS，ASR 用 gs:// 识别。
	•	bucket 示例：pikppo-asr-audio
	•	region：选离你近的（Sydney 用户可选 Australia 区域）

2.2 IAM 权限（必须）

给你现有 service account（你 JSON 那个）增加 bucket 权限：
	•	Storage Object Creator（足够上传）
	•	（可选）Storage Object Viewer（方便调试）
	•	v1 不写删除逻辑的话，不需要 delete 权限

2.3 Lifecycle（强烈建议）

bucket 设置生命周期规则：删除 asr/ 前缀下 7 天前的对象。
这样你代码里不用写清理逻辑，安全省事。

⸻

3. ASR Google 代码整改（核心）

3.1 停止 chunk 模式（≤3分钟直接整段）

你的日志已经证明 chunk 模式既没切对，又仍然走 inline。

整改策略：
	•	删除/绕过 _transcribe_chunked() 路径
	•	对 ≤3min 音频：永远走 _transcribe_gcs_uri() 一次识别

判断标准（任选一个）：
	•	直接用视频时长（ffprobe）
	•	或简单点：你的业务保证每集≤3min，直接不切

3.2 统一 ASR 输入音频规格（必须）

Demucs 的 vocals.wav 常见是 44.1k stereo，体积会巨大。

整改：在 asr_google.py 识别前加一步转码：
	•	输入：xxxx/dub/1/1-vocals.wav
	•	输出：xxxx/dub/1/1-vocals-16k.wav

转码参数固定：
	•	-ac 1 -ar 16000 -c:a pcm_s16le

这样 3 分钟音频大致 5–6MB，稳定。

3.3 改用 GCS URI（必须）

把 _transcribe_single() 从：
	•	❌ RecognitionAudio(content=...)
改成：
	•	✅ RecognitionAudio(uri="gs://...")

上传后再识别：
	•	gs://<bucket>/asr/<video_stem>/vocals_16k.wav

3.4 错误处理（必须）

针对 STT 调用增加 3 类处理：
	•	InvalidArgument：通常是 config/audio 不匹配（采样率/编码）
	•	PermissionDenied：bucket IAM 不对
	•	DeadlineExceeded：网络/服务波动，重试一次即可（≤3min 很少发生）

⸻

4. 配置与环境变量规范（v1 定死）

你现在用 GOOGLE_APPLICATION_CREDENTIALS 纠结多项目问题是对的。v1 推荐：

4.1 本地支持多项目：用“显式 creds path 参数”
	•	CLI 增加：--gcp-cred /path/to/gcp-pikppo-speech.json
	•	代码内部优先用这个 path 初始化 Speech + Storage client
（不要强依赖全局 env）

4.2 仍保留 env（用于上云）
	•	GOOGLE_APPLICATION_CREDENTIALS=/abs/path/to/xxx.json（可选）
	•	GCS_ASR_BUCKET=pikppo-asr-audio

优先级规则（写死）：
	1.	CLI --gcp-cred
	2.	env GOOGLE_APPLICATION_CREDENTIALS
	3.	报错：缺凭证

⸻

5. episode 级缓存（可选但建议）

5.1 ASR 缓存（强烈建议）

因为你会反复调 pipeline（翻译、声线），ASR 是付费的。
	•	缓存文件：xxxx/dub/1/1-zh.srt
	•	命中规则：只要文件存在且非空，就跳过 ASR
	•	增加 --force-asr 参数用于强制重跑

v1 不需要做哈希校验，工程上够用。

5.2 TTS segment 缓存（建议）

按 episode 维度：
	•	xxxx/dub/1/.cache/tts/azure/segments/<key>.wav
	•	key = text_norm + voice_id + prosody + format + engine_ver

命中后直接复用 segment，避免重复合成。

同样提供：
	•	--force-tts

⸻

6. 端到端 pipeline 行为（整改后）

以 vsd dub-en xxxx/1.mp4 为例：
	1.	输出目录：xxxx/dub/1/
	2.	提取音频：1.wav
	3.	Demucs：1-vocals.wav
	4.	转码：1-vocals-16k.wav（固定16k mono）
	5.	上传到 GCS：gs://bucket/asr/1/vocals_16k.wav
	6.	Google STT（URI）：输出 1-zh.srt + diarization speaker tags
	7.	翻译：输出 1-en.srt
	8.	TTS（Azure）：输出 1-tts.wav
	9.	对齐：输出 1-tts-aligned.wav
	10.	混音/合成：输出最终 mp4（如果你做）

⸻

7. 你现在遇到的报错会如何被彻底消灭？
	•	Request payload size exceeds 10MB
✅ 只传 URI，不传 bytes → 不存在 payload 10MB 问题
	•	Inline audio exceeds duration limit
✅ 不用 inline → 不存在 duration limit 问题

而且你不再需要 chunk 模式（它只会引入更多问题）。

⸻

8. v1 验收标准（你跑一遍就知道成没成）
	1.	vsd dub-en xxxx/1.mp4
	•	ASR 这一步日志里必须出现：gs://...
	•	且不再出现 “splitting into chunks”
	2.	识别能返回结果并生成 xxxx/dub/1/1-zh.srt
	3.	重跑一次（不改任何东西）：
	•	ASR 应直接复用（命中缓存）
	•	TTS 如果你加了 segment cache，也应大量命中

⸻

9. 你需要现在立刻准备的两样东西（才能开工）
	1.	GCS bucket 名称（你要用哪个）
	2.	你 service account 是否已经给 bucket 加了 Storage Object Creator

---------


v1 GCS 最终规范（写死）

Bucket
	•	pikppo-asr-audio

输入视频示例
	•	videos/dbqsfy/1.mp4

命名规则
	•	series = dbqsfy（父目录名）
	•	stem = 1（文件名不含扩展名）

幂等 Hash（唯一标准）
	•	h = md5(vocals.wav 的 bytes)[:12]

⸻

唯一必须上传的对象

gs://pikppo-asr-audio/asr/dbqsfy/1-vocals-<h>.wav

仅此一个对象；不上传 source/meta/中间 JSON。

⸻

幂等上传规则（必须）
	1.	本地生成 vocals.wav
	2.	计算 h
	3.	目标 key：asr/{series}/{stem}-vocals-{h}.wav
	4.	若对象已存在 → 直接复用，不上传
	5.	不存在才上传

⸻

生命周期（省钱，写死）
	•	Prefix: asr/
	•	Age: 28 days
	•	Action: Delete

⸻

Pipeline 只需传递
	•	gcs_uri = gs://pikppo-asr-audio/asr/dbqsfy/1-vocals-<h>.wav

这就是 v1 的最终答案。