1）按照SSOT中utterance粒度进行翻译，保证utterance的时间窗口不变
2）翻译时，根据utterance的语速*系数k，控制翻译长度，若语速过快，则k=1,若语速正常，则k=1.15, 若语速偏慢则k=1.2
3）如果英文长度超限，则可以扩展移utterance的end_time时间轴，不超过120–250ms，且不能与下一utterance的start_time时间重叠 
4）如果不满足长度限制条件，则重新翻译，保证长度符合要求。 
5）翻译完成后，在保证不跨 utterance 边界的前提下，允许在一个 utterance 时间窗口内自由做语义重断句

下面给你一份可直接落地的 MT 方案，严格按你 1~5 条思路展开（不发散），把“怎么计算长度 / 怎么判定语速快慢 / 怎么重试 / 怎么重断句”都写成工程可实现的规则。

⸻

MT 方案（基于 SSOT utterance，带语速预算、end 微延长、可重断句）

0) 输入/输出边界

输入
	•	SSOT：utterances[]
	•	utt_id, speaker, start_ms, end_ms
	•	speech_rate.zh_tps（你已在 SSOT v1.2 里计算好）
	•	cues[]（原始中文骨架：start/end + text）

输出（翻译产物单独存储，不回写 SSOT）
	•	TranslationSet.en.by_utt[utt_id]：
	•	end_ms_final（= end_ms 或延长后）
	•	segments[]（英文字幕段：start/end/text；不跨 utterance 边界）

⸻

1) 按 SSOT utterance 粒度翻译，时间窗口不变

1.1 翻译单元
	•	每个 utterance 作为一个翻译单元：
	•	zh_merged = concat(cues[i].source.text)（仅用于翻译输入）
	•	window_ms = end_ms - start_ms

1.2 硬约束
	•	不跨 utterance：英文产物只允许落在 [start_ms, end_ms_final]，且 end_ms_final 只允许微调（见第 3 条）

⸻

2) 用语速 * k 控制翻译长度（k 随语速档位变化）

你给的规则是：
	•	语速过快：k = 1.0
	•	正常：k = 1.15
	•	偏慢：k = 1.2

关键是要把“过快/正常/偏慢”变成可计算阈值（工程上必须量化）。

2.1 语速指标：zh_tps
	•	来自 SSOT：speech_rate.zh_tps
	•	单位：tokens/sec（你的 ASR token≈汉字，够用）

2.2 语速分档（建议默认阈值，可后续用数据校准）

给一个直接可用的初始阈值（你上线后可从数据回归再调）：
	•	fast：zh_tps >= 5.5 → k = 1.0
	•	normal：4.0 <= zh_tps < 5.5 → k = 1.15
	•	slow：zh_tps < 4.0 → k = 1.2

解释：中文 4~5.5 tps 大体是“正常到偏快”的口语区间；>5.5 进入“很赶”的区间；<4 往往语速慢、拖音多。原型先这么定，后面用样本标注回归即可。

⸻

3) 英文长度超限时，允许扩展 utterance end_time（120–250ms，且不重叠）

这里要把“英文长度”变成“预计 TTS/阅读耗时”，否则没法比较窗口。

3.1 英文时长估计

按字符速 CPS 估计（避免分词差异）
	•	en_chars = count_letters_digits(en_text)（不含空格）
	•	en_cps = 12 ~ 16（默认 14）
	•	en_est_ms = (en_chars / en_cps) * 1000


3.2 长度预算（基于 utterance 语速 + k）

你想要的是“根据语速预算控制英文长度”，可以这样落地：

预算思想
	•	中文 utterance 的“承载能力”来自它的时间窗和语速档位（k）
	•	定义一个“基准英语可读/可配音速度”，把中文时间窗映射到英文可用时间

实现（最简单可落地）
	•	budget_ms = window_ms * k
	•	其中 k 由语速档位决定（1.0 / 1.15 / 1.2）

然后比较：
	•	若 en_est_ms <= budget_ms → 通过
	•	否则进入 end 扩展与重翻译流程

注意：这里的 k 直接作用于时间预算最直观；你也可以把 k 理解为“允许英文比中文窗口长多少”，完全符合你描述。

3.3 end_time 扩展规则（严格按你要求）

当 en_est_ms > budget_ms：
	•	需要额外时间：need_ms = en_est_ms - budget_ms
	•	允许扩展上限：extend_cap_ms ∈ [120, 250]
	•	原型建议：固定 extend_cap_ms = 200（别搞动态，先跑通）
	•	还必须满足不与下一句重叠：
	•	no_overlap_cap_ms = next_utt.start_ms - end_ms - safety_gap_ms
	•	safety_gap_ms 建议 60ms（防抖）

最终可扩展：
	•	extend_ms = min(need_ms, extend_cap_ms, max(0, no_overlap_cap_ms))
	•	end_ms_final = end_ms + extend_ms

若 extend_ms > 0，再用 budget_ms2 = budget_ms + extend_ms 重新判定：
	•	若 en_est_ms <= budget_ms2 → 通过
	•	否则 → 进入第 4 条重翻译

⸻

4) 不满足长度限制则重新翻译，保证长度符合要求

这一步落地的关键是：把“长度约束”变成明确的模型指令 + 自动验证循环。

4.1 重翻译触发条件
	•	在 end 扩展后仍超限：en_est_ms > budget_ms2

4.2 重翻译策略（建议最多 2~3 次，避免死循环）
	•	Retry 1：压缩表达（保留信息不冗余）
	•	Retry 2：更强压缩（允许省略语气词/重复信息）
	•	Retry 3（可选）：改为更短句式（主动语、去从句）

4.3 给模型的硬约束提示（可落地写进 prompt）

你给模型一段明确的约束，不要“尽量”，要“必须”：
	•	必须保持原意
	•	必须更短
	•	目标英文预计时长 ≤ X ms
	•	禁止添加新信息
	•	尽量用短句、去掉填充词

其中 X = budget_ms2（最终预算）

你不用让模型输出“词数”，你只要让它“更短且必须满足时长预算”，再由你这边验证失败就重试。

4.4 验证函数（统一判定）

每次模型输出后统一走：
	•	en_est_ms = estimate(en_text)
	•	pass iff en_est_ms <= budget_ms2

⸻

5) 翻译完成后：不跨 utterance 边界，允许窗口内自由语义重断句

这里你要的是：utterance 为硬边界，内部可重排断句。

5.1 重断句输入
	•	en_text（最终通过预算的英文整句/整段）
	•	cues[]（提供窗口骨架：每个 cue 的 start/end）

5.2 重断句输出
	•	segments[]（英文字幕段），必须满足：
	•	所有 segments 的 start_ms/end_ms 落在 [utt.start_ms, end_ms_final]
	•	不跨 utterance
	•	segments 可与 cues 一一对应，也可 1 对多/多对 1（只要不跨边界）

5.3 最稳的工程落地（推荐 v0 做法：按 cues 窗口分配）

因为你已经有 cue 后处理逻辑，我给一个最通用的“分配器”：
	1.	先把 en_text 语义断句（英文标点/连词规则）得到 sentences[]
	2.	然后按 cues 的时间窗，做“长度比例分配”：
	•	total_ms = end_ms_final - start_ms
	•	每个 cue 的窗口 cue_ms = cue.end - cue.start
	•	给每个 cue 分配大致字符/词配额：quota = total_len * (cue_ms / total_ms)
	3.	按 quota 把 sentences/短语切片填进各 cue 段，生成：
	•	segment[i].start_ms = cue[i].start_ms
	•	segment[i].end_ms = cue[i].end_ms（最后一个可用 end_ms_final）

这样你就实现了：
	•	start 完全对齐 cue（视觉稳定）
	•	end 可吃到延长
	•	不跨 utterance
	•	语义断句可以在 cue 内或 cue 间调整（按 quota）

如果你后处理已经有“断句/分配器”，那你只要把输入从“中文 cue”换成“英文整段 + cues 窗口”即可。

⸻

关键参数（原型建议默认值，别纠结）
	•	语速分档阈值：
	•	fast ≥ 5.5 tps；normal 4.0~5.5；slow < 4.0
	•	safety_gap_ms = 60
	•	extend_cap_ms = 200（落在你说的 120–250ms 中间）
	•	英文时长估计：
	•	词速 en_wps = 3.0（或字符速 en_cps = 14）

⸻

端到端流程（可直接实现）

对每个 utterance：
	1.	zh_merged = concat(cues.text)
	2.	k = pick_k(zh_tps)
	3.	budget_ms = window_ms * k
	4.	en_text = translate(zh_merged, target_budget_ms=budget_ms)（第一次）
	5.	en_est_ms = estimate(en_text)
	6.	若 en_est_ms > budget_ms：
	•	计算 extend_ms，得 end_ms_final
	•	budget_ms2 = budget_ms + extend_ms
	7.	若仍超：en_est_ms > budget_ms2：
	•	retry translate（更短），直到 pass 或达到重试上限
	8.	pass 后：
	•	segments = resegment(en_text, cues, end_ms_final)（不跨边界）
	9.	写入 TranslationSet：
	•	utt_id -> {end_ms_final, segments}

-----------
下面我把你贴的两段内容重新整理成一份“最终定版方案”：
	•	以 pipeline phase 为主线（符合你 vsd run --from/--to 的原子 phase 语义）
	•	将原先 Phase1/2/3（MT/Reflow/Export）收敛到两个 phase：mt（调模型） + align（不调模型）
	•	保留你原方案里所有关键点：预算(k)、end 轻微延长、utterance 边界、不跨界重断句、落盘、校验、输出 en.srt

⸻

方案定版：将字幕翻译拆为 mt + align

0) 总体目标与边界
	•	SSOT（sub 输出）：只保存原始事实结构（utterance→cues，cue 无 target），只读
	•	mt phase（调模型）：只做机器翻译与重试，输出英文整段 string（无时间、无断句）
	•	align phase（不调模型）：把英文整段映射到时间轴，允许 end 微延长，完成重断句并生成 en.srt
	•	原子性：每个 phase 要么全做要么不做，不支持部分执行
	•	落盘：每个 phase 输出固定 artifacts，便于重跑/debug/回放

⸻

1) Pipeline 拓扑（定版）

原来：

demux → asr → sub → mt → tts → mix → burn

改为：

demux → asr → sub → mt → align → tts → mix → burn


⸻

2) CLI usage（枚举更新）

vsd run --to   {demux,asr,sub,mt,align,tts,mix,burn}
        --from {demux,asr,sub,mt,align,tts,mix,burn}

典型用法：
	•	只调模型（只翻译）

vsd run --from sub --to mt

	•	不调模型（只对齐/断句/出 srt）

vsd run --from mt --to align
# 或已有对齐产物时只重跑对齐
vsd run --from align --to align

	•	全流程

vsd run --to burn


⸻

3) 输入数据（来自 sub phase 的 SSOT）

SSOT v1.2（只读），关键字段：
	•	utterance：
	•	{utt_id, speaker, start_ms, end_ms, speech_rate.zh_tps, cues[]}
	•	cue：
	•	{cue_id, start_ms, end_ms, speaker, source.text, emotion}
	•	不包含 target

⸻

Phase: mt（Machine Translation，调模型）

3.1 一句话定义

按 SSOT 的 utterance 粒度做翻译与重试，只产出英文整段文本（不带时间轴、不带断句）。

3.2 输入
	•	artifacts/sub/ssot.v1.2.json

3.3 输出（原子产物，必须齐）
	•	artifacts/mt/mt_input.jsonl
	•	artifacts/mt/mt_output.jsonl

mt_input.jsonl（每行一个 utterance）

{
  "utt_id":"utt_0001",
  "source":{"lang":"zh","text":"(由 cues 合并得到的中文)"},
  "constraints":{"window_ms":6620,"zh_tps":4.91,"k":1.15,"budget_ms":7613}
}

预算计算（k 规则）
	•	window_ms = end_ms - start_ms
	•	k 选择：
	•	快：k=1.0
	•	正常：k=1.15
	•	慢：k=1.2
	•	budget_ms = window_ms * k
	•	阈值建议先配置写死（例：fast≥5.5，slow<4.0）

mt_output.jsonl（每行一个 utterance，只含英文 string）

{
  "utt_id":"utt_0001",
  "target":{"lang":"en","text":"I spent ten years in prison. I was framed."},
  "stats":{"en_est_ms":3850,"budget_ms":7613,"retries":0}
}

3.4 mt phase 内部规则（严格）
	•	✅ 可重试：直到满足 budget_ms 或达到重试上限
	•	✅ 输出只包含英文整段文本 + 本地估算 en_est_ms
	•	❌ 不输出 segments
	•	❌ 不做 end 延长
	•	❌ 不生成 srt
	•	❌ 不依赖 cues 的时间切片（只用合并后的中文文本）

⸻

Phase: align（Alignment / Subtitle Timing，不调模型）

4.1 一句话定义

把 mt 输出的英文整段文本映射到 SSOT 的时间骨架：
允许 utterance end 微延长，并在 utterance 内重断句生成 segments[]，最后导出 en.srt。

4.2 输入
	•	artifacts/sub/ssot.v1.2.json
	•	artifacts/mt/mt_output.jsonl

4.3 输出（原子产物，必须齐）
	•	artifacts/align/reflow.jsonl
	•	artifacts/align/en.srt

reflow.jsonl（每行一个 utterance：对齐后的字幕段）

{
  "utt_id":"utt_0001",
  "lang":"en",
  "end_ms_src":11900,
  "end_ms_final":12050,
  "segments":[
    {"start_ms":5280,"end_ms":6580,"text":"I spent ten years in prison.","cue_refs":["cue_0001"]},
    {"start_ms":6580,"end_ms":12050,"text":"I was framed.","cue_refs":["cue_0002"]}
  ],
  "stats":{"extend_ms":150}
}

4.4 align phase 内部规则（严格）

(1) end 延长（可选）
	•	允许 extend_ms 不超过 120–250ms（建议配置落 max_extend_ms=200）
	•	且必须不与下一 utterance 重叠：
	•	end_ms_final < next_utt.start_ms - safety_gap_ms
	•	safety_gap_ms 建议 60ms

计算建议：
	•	need_ms = en_est_ms - budget_ms
	•	no_overlap_cap = next_start_ms - end_ms_src - safety_gap_ms
	•	extend_ms = min(need_ms, max_extend_ms, max(0, no_overlap_cap))
	•	end_ms_final = end_ms_src + extend_ms

(2) 延长后仍无法容纳怎么办？
	•	❌ align 不允许调模型
	•	align 只返回失败原因（例如 need_retry=true），要求重新跑 mt（更强压缩重翻译）

(3) 重断句（本地算法实现）
	•	不跨 utterance 边界
	•	在一个 utterance 时间窗内允许自由语义断句
	•	默认按 cues 对齐时间骨架：
	•	segment.start = cue.start
	•	segment.end = cue.end（最后一个可吃 end_ms_final）
	•	断句策略建议：
	•	优先英文标点 .?!,;:
	•	超长时允许空格切分
	•	按 cue 时长比例分配字符/词配额（quota）

(4) 生成 en.srt
	•	汇总全片 segments，按 start_ms 排序输出 SRT
	•	清洗可选：
	•	丢弃空文本
	•	相邻间隔过小可微调 end（不动 start）

⸻

5) 两个 phase 的接口边界（写死，防混层）

mt 输出保证
	•	每个 utterance 一条（utt_id 全覆盖）
	•	target.text 为英文整段（single string）
	•	stats.en_est_ms 已本地估算
	•	不出现任何时间字段（start/end/cue_refs/segments）

align 输出保证
	•	segments 不跨 utterance
	•	segments 时间合法（start < end）
	•	end_ms_final 不与下一 utterance 重叠
	•	en.srt 必须生成（否则 phase 失败）

⸻

6) 目录结构（落地即用）

artifacts/
  sub/ssot.v1.2.json

  mt/
    mt_input.jsonl
    mt_output.jsonl

  align/
    reflow.jsonl
    en.srt


⸻

7) 关键校验点（可自动 assert）

mt
	•	target.text 非空
	•	en_est_ms 可计算
	•	retries 不超过上限

align
	•	seg.start >= utt.start
	•	seg.end <= end_ms_final
	•	全局 segments 不重叠（或允许极小间隙规则一致）
	•	end_ms_final <= next_start - safety_gap

srt
	•	全局 start 单调递增
	•	每条 start < end
	•	文本不为空（允许极短但不允许空）

⸻------------------------
OK，直接定 <sep> 方案，给你一个“可以立刻落代码”的定版。不兜圈子。

⸻

<sep> 方案（定版）

目标（一句话）

在 mt_input 阶段显式保留 cue 边界，使翻译结果可被 align 阶段稳定、可逆地断句。

⸻

1️⃣ <sep> 的定义（写死）
	•	<sep> = 轻微停顿 / 语义弱边界
	•	不是句号
	•	不是强断句
	•	不要求模型在英文中保留 <sep> 原样

⸻

2️⃣ mt_input.jsonl 的合并规则（必须）

原始 cues

cue1: 哈哈哈哈哈
cue2: 师傅
cue3: 你尖在这呢
cue4: 嫂子

合并后（mt_input.source.text）

哈哈哈哈哈 <sep> 师傅 <sep> 你尖在这呢 <sep> 嫂子

JSON 示例

{
  "utt_id": "utt_0001",
  "source": {
    "lang": "zh",
    "text": "哈哈哈哈哈 <sep> 师傅 <sep> 你尖在这呢 <sep> 嫂子"
  },
  "constraints": {
    "window_ms": 6620,
    "zh_tps": 4.91,
    "k": 1.15,
    "budget_ms": 7613
  }
}


⸻

3️⃣ mt phase 的 prompt 约束（必须加）

这是 <sep> 方案能稳定工作的关键，否则模型可能乱处理。

在 system / instruction prompt 中加这一条（固定文案即可）：

<sep> indicates a light pause between phrases.
It is NOT a sentence boundary.
Translate naturally and keep the meaning.

不需要要求模型输出 <sep>，只要求理解。

⸻

4️⃣ mt_output.jsonl 的预期形态

模型通常会输出类似：

Haha, Master, you’re standing right here, sister-in-law.

或：

Haha—Master—you’re right here, sister-in-law.

注意：
	•	<sep> 大概率不会原样出现在英文中（这是 OK 的）
	•	英文中会自然产生：
	•	,
	•	—
	•	短停顿结构
这些就是 align 阶段的切点线索

⸻

5️⃣ align 阶段如何“利用 <sep>”（核心）

原则（写死）

align 不依赖模型是否保留 <sep>，
而是依赖：<sep> → 英文自然停顿结构。

实际做法

在 align 阶段：
	1.	优先按 cue 时间骨架分段
	2.	在分配英文文本时：
	•	优先在英文的 , . ? ! — 等标点处分割
	•	若没有标点，则：
	•	按 cue 时长比例切词
	3.	<sep> 的作用已经完成：
它在翻译阶段“诱导模型产生可切分结构”

⸻

6️⃣ 为什么 <sep> 方案是最稳的（对比结论）

方案	问题
不加分隔	下游不可解 ❌
中文逗号 ，	会被模型当成强语义，有时过度断句
空格	对中文几乎没用
<sep>	语义可控 + 工程可逆 + 最稳 ✅


⸻

7️⃣ 工程级不变量（直接写 assert / 注释）

- mt_input 合并 cues 必须插入 <sep>
- <sep> 只存在于 mt_input，不回写 SSOT
- mt_output 不要求保留 <sep>
- align 阶段不依赖 <sep> 原样存在


⸻

8️⃣ 一句话拍板（最终）

mt_input 合并 cues 时统一使用 <sep>，
这是字幕翻译链路中“唯一可控的弱边界信号”。

如果你愿意，下一步我可以直接帮你做两件事之一（你选）：
	1.	给 align 阶段一个“英文切分优先级算法（伪代码）”
	2.	给 <sep> 在不同 gap / speaker 情况下是否插入的规则表（进阶版）

--------
行，给你一份完整、能直接落地的优化方案，严格基于你现在的事实：
	•	整集文本就在 asr-result.json -> result.text（直接用，不造中间产物） ￼
	•	同时它还有 result.utterances[] 分句，并带 speaker / emotion 等信息（可选增强） ￼
	•	你已确定：SSOT 用 <<NAME_i:原文>>，mt_output.jsonl 直接输出最终可展示英文（不留占位符）

⸻

0) 总体目标与边界

目标：
	•	MT 不再出现 “three tips / three points” 这种误翻，尤其是牌桌黑话（如 “三条 / 胡了 / 三张K”） ￼
	•	口语、碎句、人物关系（哥/嫂子/老弟）翻得自然，不逐字
	•	输出 mt_output.jsonl 就是最终文本：不含 <sep>、不含 <<NAME_…>>

边界：
	•	SSOT 不需要“整集内容”
	•	整集语境从 asr-result.json 直接拿
	•	不做复杂的“发布点锁定”；你采用 first-write-wins（第一次命名即固定）

⸻

1) Episode Context 从哪里取（定案）

1.1 直接取整集上下文（零加工）
	•	episode_context_text = asr.result.text ￼

这段文本已经是你要的“整集剧本串起来的上下文”，无需拼接、无需缓存文件。

1.2 可选增强：提取“风格信号”（不作为正文）

如果你想更稳（尤其是嫂子那种“刀子嘴”语气），可以从 result.utterances[].additions 取：
	•	speaker
	•	emotion / emotion_degree

这些字段在 utterances 里是现成的。 ￼

这一步只是给模型“风格提示”，不影响对齐，不增加复杂度。

⸻

2) SSOT 输入规范（你已经走对了）

每个 utt.source.text：
	•	保留 <sep> 做口语节奏提示
	•	人名用 <<NAME_i:原文>>（自描述）

你这个例子形式是对的。 ￼

同时：不再需要额外 name_map: {"<<NAME_0>>": "平安"}
因为原文已内嵌在占位符里（你已确认过这条路线）。

⸻

3) Prompt 结构（最终模板，可直接塞代码）

System（硬规则）
	•	你要模型做“最终输出”，不是吐占位符

You are a professional subtitle translator for a crime drama.

Rules:
1) The input may contain <<NAME_i:...>> which is a Chinese personal name.
   Translate the name into English (pinyin or surname-based). Do NOT invent Western names.
   Do NOT translate name meanings.
2) Translate naturally. Do NOT translate word by word.
3) This dialogue includes gambling / card-game slang. Use natural English equivalents.
4) Output must be clean English for subtitles:
   - Remove all <<NAME_i:...>> placeholders (render the translated name).
   - Remove <sep> separators (use punctuation/pauses naturally).
Return ONLY the final English text.

User（上下文 + 当前句）

把你给的 4 点融合成 4 段（固定顺序）：
	1.	剧情简介（你那段中文可以用，但更推荐英文版短简介；先不折腾也行）
	2.	Episode Context：直接贴 asr.result.text（或截断到合理长度）
	3.	Domain Hint：赌博/牌桌行话
	4.	Focus：当前 utt.source.text

Plot overview:
于平安蒙冤背负杀亲罪名...（你给的那段）

Episode dialogue context:
{asr.result.text}

Context: This dialogue includes gambling and card-game slang. Use natural English equivalents.

Translate ONLY this utterance into natural English for subtitles:
{ssot_utt.source.text}

由于你整集就这一段文本（不长），直接塞 result.text 非常合适。 ￼

⸻

4) 名字一致性（first-write-wins，极简落地）

你既然要 mt_output.jsonl 直接出最终英文名，就需要一个最小缓存（内存或项目级 JSON 都行）：
	•	name_en_map: Dict[str, str]  // key 用 NAME_i 或用原文都行（我建议用原文“平安”更直观）

规则
	•	第一次遇到 <<NAME_i:平安>>：
	•	让模型按规则翻成英文名（例如 “Ping An”）
	•	立刻写入缓存
	•	后续再遇到 “平安”：
	•	强制使用缓存值，不再让模型自由发挥

这样你永远不会出现同名漂移。

你文件里“平安 / 平安哥”重复出现很多次，特别需要这个。 ￼

⸻

5) 行话翻译稳定性（避免 three tips 的关键）

你这里的行话是 硬证据：三条 / 胡了 / 给钱给钱 / 三张k ... 都在 ASR 全文里出现。 ￼
而在 utterances 里也能定位到，比如：
	•	“三条。” ￼
	•	“胡了！” ￼
	•	“哈哈哈，给钱给钱！” ￼

最小有效增强：小词表（写死在 prompt 里）

不用算法，不用分类器，直接写 8–12 条就能救命：

Slang glossary:
- 三条 = three of a kind
- 胡了 = I’ve won! / I’m in!
- 给钱给钱 = pay up
- 小子你还是嫩了点 = you’re still green / you’ve got a lot to learn
- 刀子嘴豆腐心 = all bark and no bite

你不确定“蓝道中人/三个尖”具体该怎么定时，也可以先不写进词表，让模型在“赌博语境”里自然处理；等你遇到明显错译再补一条就行。

⸻

6) 输出落盘规范（mt_output.jsonl 直接可用）

强制校验（必须有）

写 mt_output.jsonl 之前做两个断言：
	•	不允许残留占位符
	•	不允许残留 <sep>

assert "<<NAME_" not in out_text
assert "<sep>" not in out_text

不通过就 fail（宁可中断，也不要静默产脏数据）。

⸻

7) 你现在这一套的“最终工作流”总结
	1.	读取整集上下文：episode_context = asr.result.text ￼
	2.	遍历 SSOT utterances：
	•	输入：ssot_utt.source.text（含 <<NAME:...>> + <sep>）
	•	Prompt：剧情简介 + episode_context + 赌博语境 + 当前 utt
	3.	模型输出：纯英文字幕句子
	4.	写 mt_output.jsonl（直接可用）
	5.	失败条件：输出仍含 <<NAME_ 或 <sep>

⸻

-----------
好，这一步非常对，而且是“工程上终于收口”的那一步。
我给你一份干净、可扩展、不会再打架的最终方案，直接按你说的：
👉 Slang Glossary 和 NameMap 都放到 dub/dict/，作为不同字典加载。

下面不废话，直接给目录结构 + 语义边界 + 加载顺序 + 强制策略。

⸻

一、最终目录结构（建议定死）

dub/
├── dict/
│   ├── names.json          # 人名词典（first-write-wins）
│   ├── slang.json          # 行话 / 黑话 / 牌桌术语
│   ├── honorifics.json     # 哥 / 嫂子 / 老弟（可选）
│   └── normalize.json     # 规范化规则（可选）

核心只有 names.json + slang.json
其他都是增强项，不影响主链路。

⸻

二、每个字典的职责边界（非常重要）

1️⃣ names.json —— “命名权威”

只干一件事：保证全项目人名一致

{
  "平安": "Ping An",
  "老黑": "Lao Hei",
  "赵萱萱": "Zhao Xuanxuan"
}

规则（必须写进代码，不写进 prompt）：
	•	第一次出现 → 写入
	•	后续出现 → 强制使用
	•	❌ 不允许模型自行发挥
	•	❌ 不允许被 slang / context 覆盖

👉 这是 highest priority（最高优先级）

⸻

2️⃣ slang.json —— “语义强制翻译表”

所有 entry 都是“不能错”的术语

{
  "三条": "three of a kind",
  "胡了": "I've won!",
  "给钱给钱": "Pay up!",
  "刀子嘴豆腐心": "all bark and no bite",
  "不墨迹": "stop dragging it"
}

规则：
	•	这是 exact match dictionary
	•	命中 → 禁止模型翻译
	•	直接替换 / 或强制 prompt 映射
	•	允许逐步补充（越跑越稳）

👉 priority 仅次于 names

⸻

3️⃣ （可选）honorifics.json

你如果想让“哥 / 嫂子 / 老弟”更统一：

{
  "哥": ["brother", "bro"],
  "嫂子": ["sister-in-law"],
  "老弟": ["kid", "little brother"]
}

通常不建议强制，只作为 prompt hint。

⸻

三、加载顺序（这是“为什么不会再出 Three条”的关键）

顺序错了，一切白搭

✅ 正确优先级（从高到低）
	1.	names.json（人名，绝对权威）
	2.	slang.json（术语，禁止误翻）
	3.	prompt rules / context
	4.	LLM 自由翻译（最后兜底）

⸻

四、两种“强制使用 slang”的正确方式（选一个）

✅ 方案 A：预处理替换（最稳，推荐）

在送进 LLM 之前：

三条。胡了！
↓
<SLANG:three_of_a_kind>。<SLANG:ive_won>！

并在 prompt 里写死：

Text inside <SLANG:...> MUST be rendered exactly as the provided English meaning.

LLM 根本没机会搞出 Three条。

⸻

✅ 方案 B：Prompt 强制 + 校验重试（少改代码）

把 slang.json 注入 System Prompt：

Hard Slang Rules (MUST follow exactly):
- 三条 = three of a kind
- 胡了 = I've won!
- 给钱给钱 = Pay up!
You MUST use these exact translations.

然后在代码里做 post-check：

if "三条" in src and "three of a kind" not in out:
    retry_with_stricter_prompt()


⸻

五、names.json 的正确接入方式（别再让模型“想名字”）

输入阶段（SSOT）

<<NAME_0:平安>>哥

翻译前（resolve name）

if "平安" not in names:
    names["平安"] = llm_translate_name("平安")

翻译后（最终渲染）

<<NAME_0:平安>> → Ping An

⚠️ LLM 不负责“最终是否用哪个名字”
它最多只是“第一次建议”。

⸻

六、最终 MT Pipeline（一步不多，一步不少）

ASR result.text  ──▶ episode context
                         │
SSOT utt.text ──▶ normalize
                 ├─ resolve names (names.json)
                 ├─ resolve slang (slang.json)
                 ▼
               LLM translate
                 ▼
           final render (no placeholders)
                 ▼
           mt_output.jsonl

强制断言（必须有）：
	•	输出不含中文
	•	输出不含 <SLANG / <<NAME
	•	slang 命中必须成功

⸻

七、一句话把这套设计钉死

names.json 决定“你是谁”，
slang.json 决定“你在干嘛”，
LLM 只是把话说顺。

你这一步把字典下沉到 dub/dict/，
等于把 “不允许犯错的东西”全部从模型脑子里拿出来了。

这是做对了方向的标志。

如果你愿意，下一步我可以：
	•	给你一份 dict loader + priority resolver 的参考实现
	•	或帮你定义 slang.json 的最小初始集（20 条以内，立刻止血）