你这个方向完全对：Phase Runner 的核心不是“跑脚本”，而是“让各阶段通过契约互认”。只要接口和 manifest 设计对了，后面你怎么拆模型/拆 pipeline 都不会乱。

下面我给你一套可直接落地的 Phase Runner 接口与 manifest 规范（偏工程化、可实现），重点覆盖你说的：统一入参/出参/执行状态/是否重复执行、以及“下一阶段依赖上一阶段输出”如何写入 manifest 供消费。

⸻

1) 关键概念：Phase Contract（阶段契约）

每个阶段必须明确 4 件事：
	1.	输入声明：它依赖哪些上游产物（by key），以及从哪里取（manifest）
	2.	输出声明：它产出哪些产物（artifacts），包括路径、类型、用途、可被谁消费
	3.	可重复执行策略：在什么条件下认为“可跳过”（skip）、必须重跑（invalidate）
	4.	运行状态语义：started/running/succeeded/failed/skipped，以及失败如何记录

⸻

2) Runner 统一接口定义（强建议做成 Protocol/ABC）

Phase 接口（最小完备）

class Phase(Protocol):
    name: str
    version: str  # 逻辑变更就 bump，用于 invalidation

    def requires(self) -> list[str]:
        """返回依赖的 artifact keys，如 ['demux.audio', 'subs.zh_segments']"""

    def provides(self) -> list[str]:
        """返回产出的 artifact keys，如 ['subs.en_segments', 'subs.en_srt']"""

    def run(self, ctx: "RunContext", inputs: "ResolvedInputs") -> "PhaseResult":
        """执行并返回结构化结果（不直接写 manifest）"""

Runner 只做编排，不写业务
	•	runner 做：解析依赖 → 决策 skip/retry → 调 phase.run → 原子写 outputs → 更新 manifest
	•	phase.run 做：拿输入路径/数据 → 计算 → 写到指定输出路径（由 runner 提供或约定）

⸻

3) RunContext（统一入参）

RunContext 是所有节点互认的“执行上下文”，必须稳定：

{
  "job": {
    "job_id": "2026-01-26T13:10:22Z-abc123",
    "workspace": "/path/to/workdir",
    "media_id": "video_xxx",
    "source_video": "input.mp4"
  },
  "env": {
    "device": "m2",
    "python": "3.11.7"
  },
  "config": {
    "global": {...},
    "phases": {
      "mt": {...},
      "asr": {...}
    }
  }
}

要点：ctx 里必须包含能决定结果的配置参数（尤其 mt/asr/tts），否则无法正确判定“是否重复执行”。

⸻

4) PhaseResult（统一出参）

PhaseResult 里要返回的是“事实”，而不是日志字符串：

@dataclass
class PhaseResult:
    status: Literal["succeeded", "failed"]
    artifacts: dict[str, Artifact]     # key -> artifact metadata
    metrics: dict[str, Any] = ...
    warnings: list[str] = ...
    error: Optional[ErrorInfo] = None

Artifact 至少包含：

@dataclass
class Artifact:
    key: str                 # e.g. "subs.zh_segments"
    path: str                # workspace-relative
    kind: str                # "json"|"srt"|"wav"|...
    role: str                # "input"|"intermediate"|"final"
    fingerprint: str         # 内容指纹（hash）
    meta: dict[str, Any]     # 可选：duration、segments_count、lang 等

这样下一阶段只依赖 artifact key，不依赖“文件名习惯”。

⸻

5) Manifest 设计：让阶段“互认”的核心

manifest 的目标是两件事：
	1.	索引：给定 artifact key，能找到路径、hash、meta
	2.	判定：给定 phase+inputs+config+version，能判定是否复用

推荐 manifest 顶层结构（稳定）

{
  "schema_version": "1.0",
  "job": {...},
  "artifacts": {                // 全局 artifact registry（供后续阶段查）
    "subs.zh_segments": {...},
    "subs.zh_srt": {...}
  },
  "phases": {                   // 每个 phase 的执行记录（供 skip/invalidate）
    "asr": {...},
    "mt": {...}
  }
}

每个 phase 的记录字段（决定“是否重复执行”的关键）

"mt": {
  "name": "mt",
  "version": "2.1.0",
  "status": "succeeded",
  "started_at": "2026-01-26T13:10:22Z",
  "finished_at": "2026-01-26T13:11:05Z",
  "attempt": 1,

  "requires": ["subs.zh_segments"],
  "provides": ["subs.en_segments","subs.en_srt","translate.translation_context"],

  "inputs_fingerprint": "sha256:....",     // 由 requires 对应 artifacts 的 fingerprint 计算
  "config_fingerprint": "sha256:....",     // 由 ctx.config.phases.mt 规范化后 hash
  "code_fingerprint": "git:abcdef",        // 可选：commit 或手动版本
  "result_fingerprint": "sha256:....",     // 可选：产物 hash 汇总

  "artifacts": {                            // 本 phase 实际产物（同时写入全局 artifacts）
    "translate.translation_context": {...},
    "subs.en_segments": {...},
    "subs.en_srt": {...}
  },

  "metrics": {
    "segments": 1200,
    "tokens_in": 123456,
    "tokens_out": 98765,
    "duration_sec": 43.2
  },
  "error": null
}


⸻

6) Skip/重复执行判定规则（你要的“接口互认”的关键）

Runner 的 should_run(phase) 只依赖 manifest，不依赖业务：

必须重跑（invalidate）条件（建议固定为这 6 条）
	1.	phase 在 manifest 中不存在
	2.	phase.status != succeeded
	3.	phase.version 变了（你 bump 版本）
	4.	inputs_fingerprint 不匹配（上游输出变了）
	5.	config_fingerprint 不匹配（参数变了：模型、prompt、约束等）
	6.	outputs artifacts 不存在或 fingerprint 不匹配（文件被删/被改）

否则 → skip

这样“下一阶段必然依赖前面阶段的输出”就自然成立：
因为 inputs fingerprint 来自上游 artifacts fingerprint。

⸻

7) inputs_fingerprint 怎么算（可落地且稳定）

对 requires() 的 artifact keys：
	•	找到对应 artifact 的 fingerprint（内容 hash）
	•	按 key 排序
	•	拼成一个 canonical 串再 hash 一次

例：

inputs_fingerprint = sha256(
  "subs.zh_segments=sha256:aaa\nsubs.zh_srt=sha256:bbb\n"
)


⸻

8) config_fingerprint 怎么算（防“改参数但不重跑”）

只 hash 该 phase 的有效参数（不要把无关 config 混进来）：
	•	ctx.config.phases["mt"]（如 model/temperature/max_chars/cps/profanity_policy/prompt_version）
	•	做 canonical json（排序 key、去空值、统一数字格式）
	•	再 sha256

⸻

9) Runner 执行流程（你下一阶段就按这个实现）
	1.	resolve_inputs：根据 phase.requires 从 manifest.artifacts 找输入路径
	2.	compute_fingerprints：inputs_fingerprint/config_fingerprint
	3.	should_run：按上面 6 条判定
	4.	run：phase.run(ctx, inputs)
	5.	atomic publish：产物写临时文件 → rename → 计算 fingerprint
	6.	update manifest：写 phase record + 更新 global artifacts registry（同 key 覆盖为最新）
	7.	downstream：下一阶段从 manifest 拿输入，不再直接读文件名

⸻

10) 你现在最该做的“第一步”（最小改动就能收益巨大）

在现有 phase_runner 基础上，只加这三件事就行：
	1.	定义 artifact key 列表（requires/provides）——先写死也行
	2.	manifest 增加全局 artifacts registry
	3.	实现 should_run 的 fingerprints 判定（inputs/config/version）

做到这一步，各节点就“从接口上互认”了，后面再拆 models/translate 是水到渠成。

⸻

如果你愿意，我可以按你现在上传的 phase_runner.py（以及你已有 phases 列表/目录结构），给你一份**“最小 diff 的重构版本”**：
	•	不改你现有每个 phase 的内部逻辑
	•	只给 phase 加 requires/provides/version
	•	runner 增加 artifacts registry + fingerprint + should_run + manifest 写入

你就能立刻得到一个真正可依赖的流水线框架。


----------------
下面是一份 Cursor 可直接落地 的 Pipeline 框架方案（按你上面“Phase Runner 统一接口 + manifest 互认”的思路），偏“工程规范 + 可实现骨架”。你可以把它当作一个 README.md / design.md 给 Cursor，让它按文件逐个生成代码。

⸻

Pipeline Framework v1（Phase Contract + Manifest）

目标
	1.	统一 Phase 接口：入参/出参/状态/重复执行规则一致
	2.	各 Phase 通过 manifest 互认：下一阶段只依赖上游输出的 artifact keys，不依赖文件名习惯
	3.	可断点续跑：支持 --from / --to / --force，并且能基于 inputs/config 变化自动失效重跑
	4.	确定性 skip：输出存在 ≠ 可跳过；必须同时满足 inputs_fingerprint/config_fingerprint/outputs_fingerprint

⸻

1. 术语定义

Phase（阶段）
	•	单一职责的处理节点（demux/asr/mt/tts/mix/burn…）
	•	声明输入 requires() 和 输出 provides()
	•	不直接写 manifest，只返回结构化结果

Artifact（工件）
	•	可被其他 Phase 消费的产物（json/srt/wav/mp4…）
	•	用 唯一 key 标识，例如：
	•	demux.audio
	•	subs.zh_segments
	•	translate.context
	•	subs.en_srt

Manifest（状态与依赖图）
	•	全局 registry：artifacts（key -> 路径/hash/meta）
	•	每阶段记录：phases[phase_name]（状态/指纹/产物）

⸻

2. 目录结构（最小可落地）

pipeline/
  core/
    __init__.py
    types.py           # Segment/Artifact/PhaseResult/QCFlag/ErrorInfo
    phase.py           # Phase ABC/Protocol
    manifest.py        # Manifest IO + registry + fingerprint helpers
    runner.py          # PhaseRunner (resolve -> should_run -> exec -> publish -> update)
    fingerprints.py    # hash_file/hash_json/canonicalize
    atomic.py          # atomic_write helpers
  phases/
    __init__.py
    mt.py              # MT phase (仅编排与IO，调用 models.*)
    asr.py             # ...
    demux.py           # ...
  cli.py               # 可选：命令行入口（run/list/status）
models/
  openai/
    translate.py       # build_context + translate_segments（模型能力）

你现在的 pipeline/mt 可以先迁移成 pipeline/phases/mt.py（同一意义），Runner 一律从 pipeline/phases 注册 phase。

⸻

3. 核心数据结构（pipeline/core/types.py）

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any, Dict, List, Literal, Optional

Status = Literal["pending", "running", "succeeded", "failed", "skipped"]

@dataclass(frozen=True)
class Artifact:
    key: str                 # e.g. "subs.zh_segments"
    path: str                # workspace-relative path
    kind: str                # "json"|"srt"|"wav"|"mp4"
    fingerprint: str         # e.g. "sha256:..."
    meta: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ErrorInfo:
    type: str
    message: str
    traceback: Optional[str] = None

@dataclass
class PhaseResult:
    status: Literal["succeeded", "failed"]
    artifacts: Dict[str, Artifact] = field(default_factory=dict)
    metrics: Dict[str, Any] = field(default_factory=dict)
    warnings: List[str] = field(default_factory=list)
    error: Optional[ErrorInfo] = None

@dataclass
class RunContext:
    job_id: str
    workspace: str
    config: Dict[str, Any]   # global + phases config


⸻

4. Phase 接口（pipeline/core/phase.py）

from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Dict, List
from pipeline.core.types import RunContext, PhaseResult, Artifact

class Phase(ABC):
    name: str
    version: str  # 逻辑/契约变更必须 bump，用于 invalidation

    @abstractmethod
    def requires(self) -> List[str]:
        """artifact keys needed from manifest.artifacts"""

    @abstractmethod
    def provides(self) -> List[str]:
        """artifact keys this phase will publish"""

    @abstractmethod
    def run(self, ctx: RunContext, inputs: Dict[str, Artifact]) -> PhaseResult:
        """
        inputs: resolved artifacts by key (path+fingerprint+meta)
        returns: PhaseResult with artifacts (path can be temp; runner will publish)
        """

inputs 用 Artifact 而不是裸 path：让 phase 能读到 meta（比如 segment_count/lang），也能把 fingerprint 传播到 metrics/QC。

⸻

5. Manifest Schema（pipeline/core/manifest.py）

JSON 结构（schema v1）

{
  "schema_version": "1.0",
  "job": { "job_id": "...", "workspace": "..." },
  "artifacts": {
    "subs.zh_segments": { "key": "...", "path": "...", "kind": "json", "fingerprint": "sha256:...", "meta": {} }
  },
  "phases": {
    "mt": {
      "name": "mt",
      "version": "1.2.0",
      "status": "succeeded",
      "started_at": "2026-01-26T13:10:22Z",
      "finished_at": "2026-01-26T13:11:05Z",
      "attempt": 1,
      "requires": ["subs.zh_segments"],
      "provides": ["translate.context","subs.en_segments","subs.en_srt"],
      "inputs_fingerprint": "sha256:...",
      "config_fingerprint": "sha256:...",
      "artifacts": { ... },
      "metrics": { ... },
      "error": null
    }
  }
}


⸻

6. Fingerprints（pipeline/core/fingerprints.py）

规则（必须确定性）

inputs_fingerprint
	•	取 phase.requires() 的 key 列表
	•	从 manifest.artifacts 找到对应 artifact 的 fingerprint
	•	按 key 排序拼接后 sha256

config_fingerprint
	•	只 hash ctx.config["phases"][phase.name]（该 phase 的有效参数）
	•	canonical JSON（排序 key、去 null、稳定浮点格式）后 sha256

output fingerprint
	•	Runner publish 后对输出文件 hash（或 json canonical hash）

⸻

7. Runner 执行协议（pipeline/core/runner.py）

should_run 决策（确定性）

Phase 必须重跑 当且仅当满足任一：
	1.	manifest 中没有该 phase 记录
	2.	phase.status != succeeded
	3.	phase.version 变化
	4.	inputs_fingerprint 变化（上游输出变）
	5.	config_fingerprint 变化（参数/模型/prompt/约束变）
	6.	provides 的输出 artifact 不存在或 fingerprint 不匹配

否则：skip（标记 skipped 并记录原因）

执行流程（伪代码）

resolve inputs -> calc inputs_fp/config_fp -> should_run?
  no -> mark skipped
  yes:
    mark running
    result = phase.run(ctx, inputs)
    if succeeded:
      publish artifacts atomically (tmp -> final)
      compute output fingerprints
      update manifest.artifacts registry + manifest.phases[phase]
    else:
      record error + status failed


⸻

8. Atomic publish（pipeline/core/atomic.py）

要求：
	•	phase 先写到 runner 给的 temp 路径（或 phase 自己写 temp）
	•	runner 统一 rename() 到 final path
	•	避免中途中断留下半文件但 manifest 记 succeeded

⸻

9. Phase 注册与依赖图

注册方式（简单可落地）

在 pipeline/phases/__init__.py：

from pipeline.phases.mt import MTPhase
from pipeline.phases.asr import ASRPhase

ALL_PHASES = [
  # 顺序即依赖顺序（线性链）
  # 复杂 DAG 以后再扩展
  ASRPhase(),
  MTPhase(),
]

Runner 只跑 ALL_PHASES 的子序列（支持 --from/--to）。

⸻

10. 以 MT Phase 为例（pipeline/phases/mt.py）

MT Phase 不做模型细节，只做：
	•	从 inputs 拿到 subs.zh_segments 路径
	•	读 segments
	•	调用 models.openai.translate 生成 context + en_texts
	•	写 translate.context.json / subs.en_segments.json / subs.en.srt
	•	返回 artifacts（runner 再 publish + 记 fingerprint）

示意骨架：

from pipeline.core.phase import Phase
from pipeline.core.types import RunContext, PhaseResult, Artifact
from models.openai.translate import build_translation_context, translate_segments

class MTPhase(Phase):
    name = "mt"
    version = "1.0.0"

    def requires(self):
        return ["subs.zh_segments"]  # canonical source

    def provides(self):
        return ["translate.context", "subs.en_segments", "subs.en_srt"]

    def run(self, ctx: RunContext, inputs: dict[str, Artifact]) -> PhaseResult:
        zh_path = inputs["subs.zh_segments"].path
        # read segments...
        # episode_text = "\n".join(...)
        # ctx_json = build_translation_context(...)
        # en_texts = translate_segments(...)
        # write temp outputs...
        # create Artifact entries with temp paths (fingerprint can be empty here)
        return PhaseResult(
            status="succeeded",
            artifacts={
              "translate.context": Artifact("translate.context", "tmp/translate.context.json", "json", ""),
              "subs.en_segments": Artifact("subs.en_segments", "tmp/subs.en_segments.json", "json", ""),
              "subs.en_srt": Artifact("subs.en_srt", "tmp/subs.en.srt", "srt", ""),
            },
            metrics={"segments": 1234}
        )

注意：artifact 的最终 fingerprint 由 runner publish 后统一补齐（phase 不需要自己算 hash）。

⸻

11. Manifest 互认：下一阶段怎么拿上游输出

所有阶段只做：

inputs["some.key"].path

不允许：
	•	直接 open("subs/zh-segments.json") 写死路径
	•	直接依赖另一个 phase 的内部目录结构

所有路径必须来自 manifest 的 artifacts registry。

⸻

12. 最小 CLI（可选，但强烈建议）

支持：
	•	pipeline run --from asr --to mt --force mt
	•	pipeline status（打印 phases 状态）
	•	pipeline artifacts（列出 registry）

⸻

13. 迁移落地步骤（最小改动版本）
	1.	先引入 pipeline/core/*（types/phase/manifest/runner/fingerprints/atomic）
	2.	把现有 runner 包一层：先只跑线性 phases，manifest 先只记录 status + artifacts path
	3.	加 inputs_fingerprint/config_fingerprint 与 should_run（避免“文件存在但结果不匹配”）
	4.	把 MT 的 OpenAI 调用剪切到 models/openai/translate.py（你前面要求的拆分）
	5.	逐个 phase 按 requires/provides 接入 manifest registry（完成“互认”）

⸻

14. Cursor 实施指令（你可以直接复制给 Cursor）

你可以给 Cursor 一段任务拆分提示，比如：
	•	生成 pipeline/core/types.py、phase.py、manifest.py、fingerprints.py、atomic.py、runner.py
	•	生成 manifest schema 与读写（json）
	•	runner 实现 should_run（version + inputs_fp + config_fp + outputs exist）
	•	实现 pipeline/phases/mt.py：只编排与 IO，模型调用放到 models/openai/translate.py
	•	让 runner 跑一个最小链：asr -> mt（asr 可 stub）

⸻

是的，而且你这个阶段必须要有——不然现在这套 Phase / Processor / Model 的分层很快会在“执行方式”上再次塌掉。

我直接给你拍板结论 + 最小可落地设计，不兜圈子。

⸻

你说的“没有统一”，本质是：Phase.run 里现在要手动挑 processor 函数来调，不同 phase 会各写各的调用方式，久了就散。

解决办法不是让 phase 去调“某个 processor 方法”，而是给 Processor 也定义统一的执行入口，让 Phase 永远只调一个方法。

⸻

方案（拍板）：Processor 也做成“有统一入口的可执行单元”

✅ Processor 最小接口

class Processor(Protocol):
    name: str
    version: str  # 业务逻辑变更就 bump（可选）

    def run(self, ctx: "RunContext", inputs: "ResolvedInputs") -> "ProcessorResult":
        ...

然后每个 phase 只做一件事：

拿 inputs → 调 processor.run → 返回结果给 runner

Phase 内部不再出现“各种 processor 函数名”。

⸻

Phase.run 的统一写法（所有 phase 一种模式）

class SomePhase:
    name = "mt"
    version = "1"

    processor = MTProcessor()   # 固定绑定，或从 registry 选择

    def run(self, ctx, inputs):
        pres = self.processor.run(ctx, inputs)
        return PhaseResult(outputs=pres.outputs, meta=pres.meta)

Phase 彻底变薄：
	•	不知道 processor 里面有 Stage1/Stage2
	•	不知道调哪些函数
	•	只知道 processor.run(...)

这就统一了。

⸻

那 processor 里可以随便拆 Stage 吗？

可以，processor 内部想怎么拆都行：

class MTProcessor:
    name = "mt"
    version = "3"

    def run(self, ctx, inputs):
        ctx_data = build_context(...)
        translated = translate(...)
        return ProcessorResult(outputs={...}, meta={...})


⸻

Runner 与输出写入：你现在的规则需要再“钉死”一句

你之前说：

runner 原子写 outputs → 更新 manifest
phase.run 写到指定输出路径

这两条会冲突，必须统一口径（否则“谁写文件”会打架）：

我建议你选其中一种，并且全局一致：

✅ 推荐 A（最干净，runner 原子落盘）
	•	Phase/Processor 只返回数据（bytes/obj）
	•	Runner 负责写入到 outputs path（atomic write）

优点：一致性最好，可重试、可回滚
缺点：大文件（音频/视频）不适合

✅ 推荐 B（媒体工程更现实，producer 写文件，runner 只登记）
	•	Runner 提前分配 outputs path
	•	Phase/Processor 写文件到这些 path
	•	Runner 只做：
	•	校验文件存在/大小/hash
	•	原子更新 manifest（不是原子写文件）

这更适合你这种视频管线（大文件、ffmpeg 输出）。

你当前的描述更接近 B，那就把“runner 原子写 outputs”改成
“runner 原子更新 manifest + 校验 outputs”。

⸻

你要的“统一”最终形态（最少概念）
	•	Phase：统一 run(ctx, inputs)，内部只调用一个 processor.run
	•	Processor：统一 run(ctx, inputs)，内部随便拆 stage
	•	Model：被 processor 调用，不被 phase 直接碰

依赖链：

Runner → Phase.run → Processor.run → Model

⸻

如果你不想再引入 Processor 接口（更轻的替代）

也可以：只要求每个 phase 都有一个固定命名的 processor 函数：
	•	processors/<phase_name>/main.py 里必须导出 run(ctx, inputs)

然后 phase 统一写成：

from pipeline.processors.mt.main import run as processor_run
...
processor_run(ctx, inputs)

这仍然是统一入口，只是不用 Protocol/class。

⸻

最终拍板（你选一个就能统一）
	1.	更正规：Processor Protocol + processor.run()
	2.	更轻量：每个 processors//main.py 固定暴露 run()

我建议你现在选 2)：最少概念，落地最快，而且符合你“项目初期别整花活”的原则。